---
title: "Salary MLR 2nd Draft"
author: "Colin Busby"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
```

```{r}
library(tidyverse)
library(randomForest)
library(parallel)
library(rpart)
library(readr)
library(janitor)
library(car)
library(MASS)
library(Hmisc)
library(rstatix)
library(forcats)
library(GGally)
library(performance)
library(caret)
library(lmtest)
```

# Intro

blahblahblah Hi

Question - How do the various stats from the ESPN website explain the salaries of NBA players?

Where data is from

Variables explained

## Data Exploration

```{r}
# Load dataset

players <- read_csv("players.csv")
active_p <- read_csv("active_players_2.csv")
```

```{r}
# Structure/Dimensions of the data.frame
str(active_p)
```

```{r}
# Number of columns containing `NA` or `NaN`
colSums(is.na(active_p))
```

## Data Cleaning

```{r}
#identifying the rows with NAs
rownames(active_p)[apply(active_p, 2, anyNA)]

#removing all `Salary` observations with NAs
ap_cl <- active_p[!(is.na(active_p$Salary)), ]
```

```{r}
# Checking for leftover `NA` after cleaning
rownames(active_p)[apply(ap_cl, 2, anyNA)]
```

```{r}
# Transforming Team,Position,College into factors
ap_cl_f <- transform (
  ap_cl,
  fTeam = as.factor(Team),
  fPosition = as.factor(Position),
  fCollege = as.factor(College)
)
```

```{r}
# Rename `fCollege` factor level "nan" as "None"
# levels(ap_cl_f$fCollege)[levels(ap_cl_f$fCollege)=="nan"] <- "None"
#levels(ap_cl_f$fCollege)
```

```{r}
str(ap_cl_f)
```

## Model Building

### Initial Graphs

```{r}
# The diagonal consists of the densities of the three variables and the upper panels consist of the correlation coefficients between the variables.

ggpairs(ap_cl_f, columns = c(9,4,6,7), cardinality_threshold = NULL)
```

```{r}
ggplot(ap_cl_f, aes(Salary)) +
  geom_histogram(bins = 30)
```

```{r}
ggplot(ap_cl_f, aes(log(Salary))) +
  geom_histogram(bins = 30)
```

### Full(Initial) Model

```{r}
lm1 <- lm(Salary ~ fTeam+fPosition+fCollege+Age+Height_i+Weight, data=ap_cl_f)
summary(lm1)
```

#### Inital Tests

```{r}
shapiro.test(resid(lm1))
bptest(lm1)
```

### Check for Polynomial Terms

`Age`, `Height_i`, and `Weight` appear to be misspecified.

```{r}
crPlots(lm1)
```

```{r}
summary(lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,2)+poly(Height_i,2)+poly(Weight,2), data=ap_cl_f))
summary(lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,3)+poly(Height_i,3)+poly(Weight,3), data=ap_cl_f))
summary(lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,4)+poly(Height_i,4)+poly(Weight,4), data=ap_cl_f))
summary(lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,3)+Height_i+poly(Weight,2), data=ap_cl_f))
summary(lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,3)+Height_i+poly(Weight,3), data=ap_cl_f))
summary(lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,3)+Height_i+poly(Weight,4), data=ap_cl_f))
summary(lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,3)+Height_i+Weight, data=ap_cl_f))
```

The end result is that only `Age` has been misspecified, and has been re-specified as `poly(Age,3)`.

### Reduced Model

```{r}
# Removal of `fTeam` due to no significance
summary(lm2 <- lm(Salary ~ fPosition+fCollege+poly(Age,3)+Height_i+Weight, data=ap_cl_f))
```

```{r}
# Removal of `Height_i` due to no significance
summary(lm3 <- lm(Salary ~ fPosition+fCollege+poly(Age,3)+Weight, data=ap_cl_f))
```

```{r}
# Removal of `fCollege`
summary(lm4 <- lm(Salary ~ fPosition+poly(Age,3)+Weight, data=ap_cl_f))
```

```{r}
lm1 <- lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,3)+Height_i+Weight, data=ap_cl_f)
anova(lm4,lm3,lm2,lm1)
```

### Stepwise Model Selection

```{r}
lm1 <- lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,3)+Height_i+Weight, data=ap_cl_f)
summary(lm_step <- step(lm1))
```

## Model Checking

### Outliers

```{r}
# Remove outliers & high leverage from data
ap_cl_f_wo <- ap_cl_f[-which(abs(rstandard(lm_step)) > 2 | hatvalues(lm_step) > .1),]
```

```{r}
summary(lm1_wo <- lm(Salary ~ fTeam+fPosition+fCollege+poly(Age,3)+Height_i+Weight, data=ap_cl_f_wo))
summary(lm_step_wo <- step(lm1_wo))
```

### Box Cox

```{r}
boxcox(lm1,lambda=seq(-1, 1, by=0.05))
```

```{r}
BoxCoxTrans(ap_cl_f$Salary)
```

```{r}
summary(lm_step_trans <- step(lm1_trans <- lm(log(Salary)~fTeam + fPosition + fCollege + poly(Age,3) + Height_i + Weight, data = ap_cl_f)))
```

```{r}
lm_step_trans
```

### Box-Cox w/o outliers and high leverage

Very poor results compared to keeping the high leverage points and the outliers.

```{r}
boxcox(lm1_wo,lambda=seq(-1, 1, by=0.05))
```

```{r}
BoxCoxTrans(ap_cl_f_wo$Salary)
```

```{r}
summary(lm_step_trans_wo <- step(lm1_trans_wo <- lm(log(Salary)~fTeam + fPosition + fCollege + poly(Age,3) + Height_i + Weight, data = ap_cl_f_wo)))
```

### Comparing Models

```{r}
anova(lm_step,lm3,lm2,lm1)
```

```{r}
performance::compare_performance(lm1,lm2,lm3,lm_step, rank = TRUE)
```

```{r}
anova(lm_step_trans,lm1_trans)
```

```{r}
compare_performance(lm_step_trans,lm1_trans, rank = TRUE)
```

```{r}
performance::check_model(lm_step)
```

```{r}
performance::check_model(lm_step_trans)
```

```{r}
par(mfrow=c(2,2))
plot(lm_step,1:2)
plot(lm_step_trans,1:2)
```

### VIF

```{r}
round(vif(lm_step),2)
round(vif(lm_step_trans),2)
```

## Plots

```{r}
plot(hatvalues(lm_step), rstandard(lm_step_trans),xlab='Leverage', ylab='Standardized Residuals')
```

```{r}
par(mfrow=c(1,2), mar=c(4.5, 4.5, 2, 2))
plot(lm_step, 1:2)
```

```{r}
performance::check_model(lm_step)
```

## Final Model

$log(\widehat{Salary})=13.330870-0.489098(fPositionF)+0.73758(fPositionG)+0.174562(fPositionPF)+0.711135(fPositionPG)\\+0.316997(fPositionSF)+0.403881(fPositionSG)+6.769471(Age)-3.110142(Age)^2-3.153257(Age)^3+0.008296(Weight)$

### Prediction

```{r}
# Steph Curry, Age = 34, Weigth = 185, fPosition = PG, Salary = 45780966
newdata <- data.frame(fPosition='PG', Age=34, Weight = 185)
exp(predict(lm_step_trans, newdata, type='response'))
```

```{r}
# Miles McBride Age = 20, Weight = 200, fPosition = PG, Salary = 925258
newdata <- data.frame(fPosition='PG', Age=20, Weight = 200)
exp(predict(lm_step_trans, newdata, type='response'))
```

```{r}
newdata <- data.frame(fPosition=ap_cl_f$fPosition, Age=ap_cl_f$Age, Weight = ap_cl_f$Weight)
exp(predict(lm_step_trans, newdata, type='response'))
```

## Conclusion

Given that the estimated/predicted salaries are way way off, and that the adjusted $R^2$ of the `lm_step_trans` is only $0.171$, there are obviously other predictors responsible for the majority of variance in the salaries of NBA players, most likely factors such as points scored, assists, rebounds, etc.

It was never expected that `Age`, `Weight`, and `fPosition` would be responsible for explaining the majority of variance.
